{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from irc_utils import compute_score, exponential_moving_average\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Data processing\n",
    "- Each row in csv file represent one session\n",
    "- Each session is represented by\n",
    "    - periodicity, duration, total packet size, message count, number of source ports, destination port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodicity</th>\n",
       "      <th>duration</th>\n",
       "      <th>pkt_size</th>\n",
       "      <th>msg_count</th>\n",
       "      <th>src_ports_count</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>src_spec_chars</th>\n",
       "      <th>msg_spec_chars</th>\n",
       "      <th>msg_word_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2812.000000</td>\n",
       "      <td>2.812000e+03</td>\n",
       "      <td>2.812000e+03</td>\n",
       "      <td>2812.000000</td>\n",
       "      <td>2812.0</td>\n",
       "      <td>2812.000000</td>\n",
       "      <td>2812.00000</td>\n",
       "      <td>2812.000000</td>\n",
       "      <td>2812.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.295135</td>\n",
       "      <td>1.099445e+05</td>\n",
       "      <td>1.821849e+04</td>\n",
       "      <td>70.390825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43835.111664</td>\n",
       "      <td>0.24729</td>\n",
       "      <td>0.242252</td>\n",
       "      <td>4.935707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.282077</td>\n",
       "      <td>1.420831e+05</td>\n",
       "      <td>5.486989e+04</td>\n",
       "      <td>272.945468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11029.031737</td>\n",
       "      <td>0.12296</td>\n",
       "      <td>0.155530</td>\n",
       "      <td>2.973332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2063.000000</td>\n",
       "      <td>0.08330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.076900</td>\n",
       "      <td>3.250000e+01</td>\n",
       "      <td>3.210000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37876.000000</td>\n",
       "      <td>0.15790</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>2.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.293104</td>\n",
       "      <td>1.356100e+04</td>\n",
       "      <td>1.431000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43016.000000</td>\n",
       "      <td>0.21430</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>5.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.293104</td>\n",
       "      <td>2.142610e+05</td>\n",
       "      <td>9.643250e+03</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51904.000000</td>\n",
       "      <td>0.28570</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>7.362025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.134000e+06</td>\n",
       "      <td>1.145972e+06</td>\n",
       "      <td>8633.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65138.000000</td>\n",
       "      <td>0.84620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.006900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       periodicity      duration      pkt_size    msg_count  src_ports_count  \\\n",
       "count  2812.000000  2.812000e+03  2.812000e+03  2812.000000           2812.0   \n",
       "mean      0.295135  1.099445e+05  1.821849e+04    70.390825              1.0   \n",
       "std       0.282077  1.420831e+05  5.486989e+04   272.945468              0.0   \n",
       "min       0.002800  0.000000e+00  1.010000e+02     1.000000              1.0   \n",
       "25%       0.076900  3.250000e+01  3.210000e+02     2.000000              1.0   \n",
       "50%       0.293104  1.356100e+04  1.431000e+03     8.000000              1.0   \n",
       "75%       0.293104  2.142610e+05  9.643250e+03    52.000000              1.0   \n",
       "max       1.000000  1.134000e+06  1.145972e+06  8633.000000              1.0   \n",
       "\n",
       "           dst_port  src_spec_chars  msg_spec_chars  msg_word_entropy  \n",
       "count   2812.000000      2812.00000     2812.000000       2812.000000  \n",
       "mean   43835.111664         0.24729        0.242252          4.935707  \n",
       "std    11029.031737         0.12296        0.155530          2.973332  \n",
       "min     2063.000000         0.08330        0.000000         -0.000000  \n",
       "25%    37876.000000         0.15790        0.178400          2.585000  \n",
       "50%    43016.000000         0.21430        0.222200          5.114400  \n",
       "75%    51904.000000         0.28570        0.271400          7.362025  \n",
       "max    65138.000000         0.84620        1.000000         11.006900  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select model version\n",
    "# model_version = '1' \n",
    "model_version = '2'\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "\n",
    "# Import data\n",
    "# data = pd.read_csv('input/trn_data_v{}.csv'.format(model_version), delimiter=';')\n",
    "data = pd.read_csv('input/trn_data_per.csv'.format(model_version), delimiter=';')\n",
    "\n",
    "# Prepare data for training\n",
    "# Divide the data into attributes and labels\n",
    "X = data.iloc[:, 1:-1]\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# showing examples of data\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return F.sigmoid(out)\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\"\n",
    "\n",
    "def chunks(X, K):\n",
    "    batches = []\n",
    "    N = len(X)\n",
    "    for i in range(0, N, K):\n",
    "        batches.append(X[i:i+K])\n",
    "    return batches\n",
    "\n",
    "def predict(model, X_val, y_val):\n",
    "    total_cnt, correct_cnt = 0, 0 \n",
    "    y_pred = model(X_val)\n",
    "#     _, pred_label = torch.max(y_pred.data, 1)\n",
    "    pred_label = (y_pred.data > 0.5).float() * 1\n",
    "#     print(pred_label)\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 2:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 3:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 4:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 5:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 6:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 7:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 8:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 9:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 10:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 11:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 12:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 13:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 14:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 15:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 16:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 17:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 18:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 19:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 20:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 21:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 22:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 23:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 24:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 25:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 26:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 27:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 28:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 29:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 30:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 31:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 32:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 33:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 34:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 35:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 36:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 37:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 38:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 39:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 40:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 41:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 42:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 43:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 44:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 45:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 46:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 47:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 48:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 49:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 50:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 51:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 52:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 53:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 54:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 55:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 56:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 57:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 58:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 59:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 60:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 61:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 62:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 63:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 64:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 65:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 66:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 67:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 68:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 69:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 70:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 71:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 72:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 73:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 74:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 75:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 76:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 77:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 78:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 79:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 80:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 81:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 82:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 83:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 84:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 85:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 86:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 87:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 88:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 89:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 90:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 91:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 92:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 93:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 94:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 95:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 96:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 97:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 98:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 99:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n",
      "Epoch 100:\tloss: 27.63,\ttrn acc: 0.0921,\tval acc: 0.0882\n"
     ]
    }
   ],
   "source": [
    "X_train_t = torch.tensor(X_train.values).float()\n",
    "y_train_t = torch.tensor(y_train)\n",
    "\n",
    "X_val_t = torch.tensor(X_test.values).float()\n",
    "y_val_t = torch.tensor(y_test)\n",
    "\n",
    "#Number of epochs\n",
    "num_epochs = 100\n",
    "\n",
    "accs_val = []\n",
    "accs_trn = []\n",
    "K = 10\n",
    "X_batches = chunks(X_train_t, K)\n",
    "y_batches = chunks(y_train_t, K) \n",
    "\n",
    "score_trn_list = []\n",
    "score_val_list = []\n",
    "\n",
    "model = MLP(9,50,1)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-2)\n",
    "loss_criterion = nn.BCELoss()\n",
    "\n",
    "# for every x_batch, y_batch in X_batches, y_batch, run the network\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_batch).reshape(-1)\n",
    "#         print('{} VS {}'.format(model(X_batch), model.))\n",
    "#         print('out shape: {}, y_batch shape: {}'.format(out.shape, y_batch.shape))\n",
    "        loss = loss_criterion(out, y_batch.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred_val = predict(model, X_val_t, y_val_t)\n",
    "        y_pred_trn = predict(model, X_train_t, y_train_t)\n",
    "        \n",
    "        score_trn = compute_score(y_train, y_pred_trn, verbose=False)\n",
    "        score_val = compute_score(y_test, y_pred_val, verbose=False)\n",
    "        score_trn_list.append(score_trn)\n",
    "        score_val_list.append(score_val)\n",
    "    \n",
    "#     if (epoch+1) % 10 == 0:\n",
    "    print('Epoch {}:\\tloss: {:.4},\\ttrn acc: {:.4},\\tval acc: {:.4}'.format(epoch+1,loss,score_trn[7],score_val[7]))\n",
    "\n",
    "score_trn_list = np.stack(score_trn_list, axis=0)\n",
    "score_tst_list = np.stack(score_val_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[690   0]\n",
      " [ 13   0]]\n",
      "\n",
      "Sensitivity(=Recall) TPR = TP / (TP + FN):\t\t0.0\n",
      "Specificity SPC = TN / (FP + TN):\t\t\t1.0\n",
      "Precision PPV = TP / (TP + FP):\t\t\t\t0.0\n",
      "Negative Predictive Value NPV = TN / (TN + FN):\t\t0.9815\n",
      "False Positive Rate FPR = FP / (FP + TN)):\t\t0.0\n",
      "False Discovery rate FDR = FP / (FP + TP):\t\t0.0\n",
      "False Negative rate FNR = FN / (FN + TP):\t\t1.0\n",
      "Accuraccy ACC = (TP + TN) / (P + N):\t\t\t0.9815\n",
      "F1-score F1 = 2TP / (2TP + FP + FN):\t\t\t0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preneond/Documents/Work/Stratosphere/Masters-thesis/IRC-Malware-Detection/irc_utils.py:10: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  PPV = np.nan_to_num(round(TP / (TP + FP), 4))\n",
      "/Users/preneond/Documents/Work/Stratosphere/Masters-thesis/IRC-Malware-Detection/irc_utils.py:13: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  FDR = np.nan_to_num(round(FP / (FP + TP), 4))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.0, 0.9815, 0.0, 0.0, 1.0, 0.9815, 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = predict(mlp, X_val_t, y_val_t)\n",
    "compute_score(y_test, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivity(=Recall) TPR = TP / (TP + FN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_trn_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7a4c737aa328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrn_score_tpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexponential_moving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_trn_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtst_score_tpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexponential_moving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_tst_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TPR score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score_trn_list' is not defined"
     ]
    }
   ],
   "source": [
    "trn_score_tpr = exponential_moving_average(score_trn_list[:,0], 0.001)\n",
    "tst_score_tpr = exponential_moving_average(score_tst_list[:,0], 0.001)\n",
    "\n",
    "plt.title(\"TPR score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('TPR')\n",
    "plt.plot(range(len(trn_score_tpr)), trn_score_tpr, label='Train TPR',color='navy')\n",
    "plt.plot(range(len(tst_score_tpr)), tst_score_tpr, label='Test TPR',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specificity SPC = TN / (FP + TN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_score_spc = exponential_moving_average(score_trn_list[:,1], 0.001)\n",
    "tst_score_spc = exponential_moving_average(score_tst_list[:,1], 0.001)\n",
    "\n",
    "\n",
    "plt.title(\"SPC score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('SPC')\n",
    "plt.plot(range(len(trn_score_spc)), trn_score_spc, label='Train SPC',color='navy')\n",
    "plt.plot(range(len(tst_score_spc)), tst_score_spc, label='Test SPC',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision PPV = TP / (TP + FP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_score_ppv = exponential_moving_average(score_trn_list[:,2], 0.001)\n",
    "tst_score_ppv = exponential_moving_average(score_tst_list[:,2], 0.001)\n",
    "\n",
    "plt.title(\"PPV score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('PPV')\n",
    "plt.plot(range(len(tst_score_ppv)), trn_score_ppv, label='Train PPV',color='navy')\n",
    "plt.plot(range(len(tst_score_ppv)), tst_score_ppv, label='Test PPV',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Predictive Value NPV = TN / (TN + FN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_score_npv = exponential_moving_average(score_trn_list[:,3], 0.001)\n",
    "tst_score_npv = exponential_moving_average(score_tst_list[:,3], 0.001)\n",
    "\n",
    "plt.title(\"NPV score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('NPV')\n",
    "plt.plot(range(len(trn_score_npv)), trn_score_npv, label='Train NPV',color='navy')\n",
    "plt.plot(range(len(tst_score_npv)), tst_score_npv, label='Test NPV',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Positive Rate FPR = FP / (FP + TN)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trn_score_fpr = exponential_moving_average(score_trn_list[:,4], 0.01)\n",
    "tst_score_fpr = exponential_moving_average(score_tst_list[:,4], 0.01)\n",
    "\n",
    "plt.title(\"FPR score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('FPR')\n",
    "plt.plot(range(len(trn_score_fpr)), trn_score_fpr, label='Train FPR',color='navy')\n",
    "plt.plot(range(len(tst_score_fpr)), tst_score_fpr, label='Test FPR',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Discovery rate FDR = FP / (FP + TP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_score_fdr = exponential_moving_average(score_trn_list[:,5], 0.0005)\n",
    "tst_score_fdr = exponential_moving_average(score_tst_list[:,5], 0.0005)\n",
    "\n",
    "plt.title(\"FDR score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('FDR')\n",
    "plt.plot(range(len(trn_score_fdr)), trn_score_fdr, label='Train FDR',color='navy')\n",
    "plt.plot(range(len(tst_score_fdr)), tst_score_fdr, label='Test FDR',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Negative rate FNR = FN / (FN + TP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_score_fnr = exponential_moving_average(score_trn_list[:,6], 0.001)\n",
    "tst_score_fnr = exponential_moving_average(score_tst_list[:,6], 0.001)\n",
    "\n",
    "plt.title(\"FNR score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('FNR')\n",
    "plt.plot(range(len(trn_score_fnr)),trn_score_fnr, label='Train FNR',color='navy')\n",
    "plt.plot(range(len(tst_score_fnr)),tst_score_fnr, label='Test FNR',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuraccy ACC = (TP + TN) / (P + N): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_score_acc = exponential_moving_average(score_trn_list[:,7], 0.01)\n",
    "tst_score_acc = exponential_moving_average(score_tst_list[:,7], 0.01)\n",
    "\n",
    "plt.title(\"ACC score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('ACC')\n",
    "plt.plot(range(len(trn_score_acc)), trn_score_acc, label='Train ACC',color='navy')\n",
    "plt.plot(range(len(tst_score_acc)), tst_score_acc, label='Test ACC',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-score F1 = 2TP / (2TP + FP + FN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_score_f1 = exponential_moving_average(score_trn_list[:,8], 0.001)\n",
    "tst_score_f1 = exponential_moving_average(score_tst_list[:,8], 0.001)\n",
    "\n",
    "plt.title(\"F1 score\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('F1')\n",
    "plt.plot(range(len(trn_score_f1)), trn_score_f1, label='Train F1',color='navy')\n",
    "plt.plot(range(len(tst_score_f1)), tst_score_f1, label='Test F1',color=\"darkorange\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
